{
    "id": "1",
    "name": "强化学习基础",
    "type": "知识模块",
    "level": 5,
    "time": "00:00:00,600 --> 00:47:01,270",
    "content": "介绍强化学习的基本概念、模型和算法。",
    "child": [
        {
            "id": "2",
            "name": "强化学习问题场景",
            "type": "知识单元",
            "level": 4,
            "time": "00:00:08,260 --> 00:03:54,910",
            "content": "通过格子世界例子说明强化学习所面对的问题场景。",
            "child": [
                {
                    "id": "3",
                    "name": "格子世界随机性",
                    "type": "知识点",
                    "level": 5,
                    "time": "00:00:16,690 --> 00:01:30,550",
                    "content": "智能体在格子世界中采取动作时存在随机性。",
                    "child": []
                },
                {
                    "id": "4",
                    "name": "奖励类型",
                    "type": "知识点",
                    "level": 4,
                    "time": "00:02:00,430 --> 00:03:04,600",
                    "content": "即时奖励与常识奖励的区别及其作用。",
                    "child": []
                },
                {
                    "id": "5",
                    "name": "策略定义",
                    "type": "知识点",
                    "level": 5,
                    "time": "00:04:46,570 --> 00:05:16,880",
                    "content": "策略是在每个状态下推荐的动作。",
                    "child": []
                }
            ]
        },
        {
            "id": "6",
            "name": "序列决策问题",
            "type": "知识单元",
            "level": 6,
            "time": "00:05:16,890 --> 00:07:18,850",
            "content": "智能体与环境交互产生轨迹序列。",
            "child": [
                {
                    "id": "7",
                    "name": "状态与动作",
                    "type": "知识点",
                    "level": 5,
                    "time": "00:05:43,340 --> 00:06:30,280",
                    "content": "智能体在不同时间片采取动作，环境反馈奖励并改变状态。",
                    "child": []
                },
                {
                    "id": "8",
                    "name": "轨迹序列",
                    "type": "知识点",
                    "level": 5,
                    "time": "00:06:30,280 --> 00:07:18,850",
                    "content": "轨迹序列包含状态、动作、奖励及状态转移。",
                    "child": []
                }
            ]
        },
        {
            "id": "9",
            "name": "马尔可夫决策过程（MDP）",
            "type": "知识单元",
            "level": 7,
            "time": "00:08:01,750 --> 00:46:58,710",
            "content": "马尔可夫决策过程的定义及应用。",
            "child": [
                {
                    "id": "10",
                    "name": "马尔可夫过程",
                    "type": "子知识点",
                    "level": 6,
                    "time": "00:08:07,790 --> 00:13:29,210",
                    "content": "马尔可夫过程包括状态集合和状态转移模型。",
                    "child": [
                        {
                            "id": "11",
                            "name": "火星车例子",
                            "type": "子知识点",
                            "level": 5,
                            "time": "00:11:16,660 --> 00:13:18,600",
                            "content": "用火星车例子说明马尔可夫过程的状态和转移模型。",
                            "child": []
                        }
                    ]
                },
                {
                    "id": "12",
                    "name": "马尔可夫奖励过程",
                    "type": "子知识点",
                    "level": 6,
                    "time": "00:15:01,200 --> 00:18:52,540",
                    "content": "引入奖励和衰减因子扩展为马尔可夫奖励过程。",
                    "child": [
                        {
                            "id": "13",
                            "name": "累积回报计算",
                            "type": "子知识点",
                            "level": 6,
                            "time": "00:18:53,540 --> 00:22:25,610",
                            "content": "通过加权和计算累积回报，考虑奖励值和时间优先级。",
                            "child": []
                        }
                    ]
                },
                {
                    "id": "14",
                    "name": "马尔可夫决策过程",
                    "type": "子知识点",
                    "level": 7,
                    "time": "00:23:01,610 --> 00:46:58,710",
                    "content": "MDP包含状态空间、动作空间、转移模型、奖励函数和衰减因子。",
                    "child": [
                        {
                            "id": "15",
                            "name": "赛车例子",
                            "type": "子知识点",
                            "level": 6,
                            "time": "00:31:28,190 --> 00:34:42,050",
                            "content": "将赛车问题建模为MDP，包括状态、动作、转移模型和奖励模型。",
                            "child": []
                        },
                        {
                            "id": "16",
                            "name": "格子世界MDP",
                            "type": "子知识点",
                            "level": 6,
                            "time": "00:36:28,360 --> 00:38:02,400",
                            "content": "将格子世界建模为MDP，分析状态、动作、转移模型和奖励模型。",
                            "child": []
                        },
                        {
                            "id": "17",
                            "name": "奖励与策略关系",
                            "type": "子知识点",
                            "level": 6,
                            "time": "00:38:47,260 --> 00:46:58,710",
                            "content": "不同奖励设定对策略选择的影响，通过格子世界案例分析。",
                            "child": []
                        }
                    ]
                }
            ]
        }
    ]
}