### 课程简介
本课程主要介绍了强化学习的基础概念，通过格子世界问题引出序列决策问题及马尔可夫决策过程（MDP）。课程从简单的例子出发，逐步深入到马尔可夫过程、马尔可夫奖励过程，最终构建完整的马尔可夫决策过程框架。通过具体实例分析，探讨了奖励机制对智能体策略选择的影响。

### 课程大纲

#### 章节1：强化学习基础与格子世界问题
##### 主题：格子世界问题
##### 内容纲要
- **智能体行为的随机性**
  - 智能体在格子世界中的动作执行结果具有随机性，例如80%的概率到达目标位置，20%平摊到垂直方向。
- **即时奖励与常识奖励**
  - 即时奖励是每步动作获得的分数，常识奖励是在游戏结束时获得的固定奖励。
- **策略的概念**
  - 策略定义为每个状态下推荐的动作集合，解决格子世界问题的关键在于找到最优策略。

#### 章节2：序列决策问题
##### 主题：序列决策问题
##### 内容纲要
- **轨迹序列**
  - 轨迹序列包含状态、动作和奖励，表示智能体与环境交互的历史记录。
- **基本元素**
  - 序列决策问题的核心元素包括智能体、环境、状态、动作和奖励。

#### 章节3：马尔可夫决策过程（MDP）
##### 主题：马尔可夫决策过程（MDP）
##### 内容纲要
- **马尔可夫过程**
  - 马尔可夫过程由状态集合和状态转移模型组成，满足马尔可夫性质。
- **马尔可夫奖励过程**
  - 在马尔可夫过程中加入奖励机制，形成马尔可夫奖励过程。
- **累积回报计算**
  - 通过衰减因子计算累积回报，反映奖励的时间价值。
- **MDP的核心元素**
  - MDP包含状态空间、动作空间、转移模型、奖励模型和衰减因子五个核心元素。
- **策略优化**
  - 寻找最优策略以最大化期望累积回报。
- **奖励与策略的关系**
  - 不同的奖励设定会影响智能体的策略选择，例如单步代价的变化会导致路径选择的不同。